{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (main.py, line 8)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/alex/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 23\u001b[0;36m\n\u001b[0;31m    from oak_cli.evaluation.addons.flops.graph_utils.main import draw_graph\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/oakestra-cli/oak_cli/evaluation/addons/flops/graph_utils/main.py:8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from icecream import ic\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import glob\n",
    "import pathlib\n",
    "from oak_cli.utils.logging import logger\n",
    "from icecream import ic\n",
    "\n",
    "from oak_cli.evaluation.graph_utils import PALETTE\n",
    "from oak_cli.evaluation.addons.flops.graph_utils.keys import (\n",
    "    RUN_ID_KEY,\n",
    "    CPU_KEY,\n",
    "    DISK_LAST_KEY,\n",
    "    DISK_START_KEY,\n",
    "    MEMORY_KEY,\n",
    "    NETWORK_LAST_KEYS,\n",
    "    NETWORK_START_KEYS,\n",
    "    STAGE_KEY,\n",
    "    TIME_START_KEY,\n",
    "    ACCURACY_KEY,\n",
    "    LOSS_KEY,\n",
    ")\n",
    "from oak_cli.evaluation.addons.flops.graph_utils.main import draw_graph\n",
    "from oak_cli.evaluation.addons.flops.graph_utils.special_graphs import (\n",
    "    draw_box_violin_plot_for_each_stage,\n",
    "    draw_line_graph_with_all_runs,\n",
    "    draw_trained_model_comparison_graph,\n",
    ")\n",
    "from oak_cli.evaluation.addons.flops.main import EvaluationRunFLOpsProjectStage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MINUTES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_dir = get_csv_dir_for_scenario(EvaluationScenario.FLOPS)\n",
    "csv_dir = pathlib.Path(\"/home/alex/oakestra-cli/oak_cli/evaluation/addons/flops/csv/monolith_mnist_sklearn_small_without_baseimages\")\n",
    "#csv_dir = pathlib.Path(\"/home/alex/oakestra-cli/oak_cli/evaluation/addons/flops/csv/monolith_hierarchical_mnist_sklearn_small_without_baseimages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(f'{csv_dir}/evaluation_run_*.csv')\n",
    "df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "\n",
    "# Add a numerical stage ID (instead of the string) for future numerical manipulations.\n",
    "STAGE_ID_KEY = \"STAGE ID\"\n",
    "df[STAGE_ID_KEY]  =  df[STAGE_KEY].apply(lambda stage_name: EvaluationRunFLOpsProjectStage(stage_name).get_index())\n",
    "\n",
    "#trained_model_df = pd.read_csv(TRAINED_MODEL_PERFORMANCE_CSV)\n",
    "trained_model_df = pd.read_csv(csv_dir / \"trained_models.csv\")\n",
    "\n",
    "# NOTE: The CSV \"time-since-start\" values are very precise, thus they differ (slightly) between Evaluation-Runs.\n",
    "# This difference leads to issues when trying to plot them in an aggregated way.\n",
    "# To fix this we cast the floats to ints instead. I.e. we are looking at whole seconds - which is fine for this concrete use-case.\n",
    "df[[TIME_START_KEY]] = df[[TIME_START_KEY]].astype(int)\n",
    "\n",
    "MEDIAN_RUNTIME__MINUTES = round(df.groupby(RUN_ID_KEY)[TIME_START_KEY].max().median() / 60, 2)\n",
    "\n",
    "df.set_index(TIME_START_KEY, inplace=True)\n",
    "\n",
    "if USE_MINUTES:\n",
    "    df.index = df.index / 60\n",
    "\n",
    "singular_run_df = df[df[RUN_ID_KEY] == (df[RUN_ID_KEY].max() // 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Handing & Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not csv_dir.exists():\n",
    "    logger.error(f\"{csv_dir} does not exist yet!\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Graph Styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU & Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(\n",
    "    title=\"Singular Example Evaluation Run\",\n",
    "    data=singular_run_df[[CPU_KEY, MEMORY_KEY, STAGE_KEY]],\n",
    "    show_stages=True,\n",
    "    use_percentage_limits=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(\n",
    "    title=\"Evaluation Runs Average\",\n",
    "    data=df[[CPU_KEY, MEMORY_KEY, STAGE_KEY]],\n",
    "    use_percentage_limits=True,\n",
    "    #show_stages=True,\n",
    "    #stages_color_intensity=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.ecdfplot(\n",
    "    #x=STAGE_KEY,\n",
    "    #x=CPU_KEY,\n",
    "    data=df[[CPU_KEY, MEMORY_KEY]],\n",
    "    palette=PALETTE,\n",
    "    #hue=STAGE_KEY,\n",
    ")\n",
    "sns.kdeplot(\n",
    "    #x=STAGE_KEY,\n",
    "    #x=CPU_KEY,\n",
    "    data=df[[CPU_KEY, MEMORY_KEY]],\n",
    "    palette=PALETTE,\n",
    "    #hue=STAGE_KEY,\n",
    "    cumulative=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_line_graph_with_all_runs(\n",
    "    data=df,\n",
    "    y_label=\"CPU Usage (%)\",\n",
    "    key=CPU_KEY,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_line_graph_with_all_runs(\n",
    "    data=df,\n",
    "    y_label=\"Memory Usage (%)\",\n",
    "    key=MEMORY_KEY,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_box_violin_plot_for_each_stage(\n",
    "    data=df,\n",
    "    key=CPU_KEY,\n",
    "    y_label=\"CPU Usage (%)\",\n",
    "    y_lim=(0,100),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_box_violin_plot_for_each_stage(\n",
    "    data=df,\n",
    "    key=MEMORY_KEY,\n",
    "    y_label=\"Memory Usage (%)\",\n",
    "    y_lim=(40,80)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 & 2: Group by 'experiment_run' and 'stage', then sum 'time'\n",
    "#grouped = df.groupby([RUN_ID_KEY, STAGE_KEY])[TIME_START_KEY].sum().reset_index()\n",
    "\n",
    "# _df = df.copy()\n",
    "\n",
    "# # _df[\"STAGE ID\"]  =  _df[STAGE_KEY].apply(lambda stage_name: EvaluationRunFLOpsProjectStage(stage_name).get_index())\n",
    "# #_df\n",
    "# #grouped = _df.groupby(STAGE_ID_KEY)[TIME_START_KEY].sum().reset_index()\n",
    "# _df.sort_values(by=[RUN_ID_KEY, STAGE_ID_KEY], inplace=True)\n",
    "# grouped = _df.groupby([RUN_ID_KEY, STAGE_ID_KEY]).size().reset_index(name=\"count\")\n",
    "# max_count_per_stage = grouped.groupby(STAGE_ID_KEY)['count'].transform(max)\n",
    "# normalized_counts = grouped['count'] / max_count_per_stage * 100\n",
    "# type(normalized_counts)\n",
    "# # average_percentages = normalized_counts.groupby(STAGE_ID_KEY).mean().round(2)\n",
    "# # average_percentages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _df[[TIME_START_KEY]] = _df[[TIME_START_KEY]].astype(int)\n",
    "# MEDIAN_RUNTIME__MINUTES\n",
    "###########################\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "_df = df.copy()\n",
    "_df.reset_index(inplace=True)\n",
    "#_df[[TIME_START_KEY]] = (_df[[TIME_START_KEY]] * 60).astype(int)\n",
    "_df[[TIME_START_KEY]] = round(_df[[TIME_START_KEY]],2)\n",
    "grouped_by_stage_id_and_run_id_for_time_start = _df.groupby([STAGE_KEY, RUN_ID_KEY])[TIME_START_KEY]\n",
    "stage_start_times = grouped_by_stage_id_and_run_id_for_time_start.min()\n",
    "stage_end_times = grouped_by_stage_id_and_run_id_for_time_start.max()\n",
    "stage_runtimes = stage_end_times - stage_start_times\n",
    "#stage_runtimes = (stage_end_times - stage_start_times).to_frame()\n",
    "#stage_runtimes.columns\n",
    "#stage_runtimes[[STAGE_ID_KEY]]\n",
    "#stage_runtimes\n",
    "\n",
    "\n",
    "# _df.reset_index(inplace=True)\n",
    "# \n",
    "# #average_evaluation_runtime = _df.gro [TIME_START_KEY].a\n",
    "# #res = _df.groupby(RUN_ID_KEY)[TIME_START_KEY].agg()\n",
    "# res = _df.groupby(RUN_ID_KEY)[TIME_START_KEY].max().median()\n",
    "\n",
    "# res\n",
    "\n",
    "#sns.lineplot(data=stage_runtimes)\n",
    "\n",
    "# Create a new DataFrame to hold the final result\n",
    "final_df = pd.DataFrame({\n",
    "    STAGE_KEY: stage_start_times.index.get_level_values(STAGE_KEY),\n",
    "    RUN_ID_KEY: stage_start_times.index.get_level_values(RUN_ID_KEY),\n",
    "    'RUNTIME': stage_runtimes.values\n",
    "})\n",
    "\n",
    "# Set TIME_START_KEY as the index if needed\n",
    "#final_df.set_index(TIME_START_KEY, inplace=True)\n",
    "#final_df\n",
    "#print(final_df)\n",
    "\n",
    "draw_graph(\n",
    "    data=final_df,\n",
    "    plot_functions=[\n",
    "        lambda: sns.barplot(\n",
    "            data=final_df,\n",
    "            y=STAGE_KEY,\n",
    "            x=\"RUNTIME\",\n",
    "            #palette=PALETTE,\n",
    "        )\n",
    "    ], \n",
    ")\n",
    "\n",
    "# sns.barplot(\n",
    "#             data=final_df,\n",
    "#             y=STAGE_KEY,\n",
    "#             x=\"RUNTIME\",\n",
    "#             palette=PALETTE,\n",
    "#         )\n",
    "\n",
    "# sns.barplot(\n",
    "#             data=df[[CPU_KEY]],\n",
    "#             # y=STAGE_KEY,\n",
    "#             # x=\"RUNTIME\",\n",
    "#             # palette=PALETTE,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disk Space Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_singular_run_df = singular_run_df.copy()\n",
    "_singular_run_df[[DISK_START_KEY]] = _singular_run_df[[DISK_START_KEY]] / 1024\n",
    "\n",
    "draw_graph(\n",
    "    title=\"Singular Example Evaluation Run\",\n",
    "    data=_singular_run_df[[DISK_START_KEY, STAGE_KEY]],\n",
    "    y_label=\"Disk Space Change (GB)\",\n",
    "    x_lim=(0, max(_singular_run_df.index)),\n",
    "    y_lim=0,\n",
    "    show_stages=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df.copy()\n",
    "_df[[DISK_START_KEY]] = _df[[DISK_START_KEY]] / 1024\n",
    "\n",
    "draw_graph(\n",
    "    title=\"Evaluation Runs Average\",\n",
    "    data=_df[[DISK_START_KEY, STAGE_KEY]],\n",
    "    y_label=\"Disk Space Change (GB)\",\n",
    "    x_lim=(0, max(_df.index)),\n",
    "    #show_stages=True,\n",
    "    #stages_color_intensity=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_y = singular_run_df[DISK_LAST_KEY].max()\n",
    "draw_graph(\n",
    "    title=\"Singular Example Evaluation Run\",\n",
    "    data=singular_run_df[[DISK_LAST_KEY, STAGE_KEY]],\n",
    "    y_label=\"Disk Space Change Between Measurements (MB)\",\n",
    "    x_lim=(0, max(singular_run_df.index)),\n",
    "    show_stages=True,\n",
    "    stages_color_height=max_y,\n",
    "    y_lim=(0, max_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_y = df[DISK_LAST_KEY].max()\n",
    "draw_graph(\n",
    "    title=\"Evaluation Runs Average\",\n",
    "    data=df[[DISK_LAST_KEY, STAGE_KEY]],\n",
    "    y_label=\"Disk Space Change Between Measurements (MB)\",\n",
    "    x_lim=(0, max(df.index)),\n",
    "    #y_lim=(0, max_y),\n",
    "    y_lim=(0, 2000),\n",
    "    #show_stages=True,\n",
    "    #stages_color_intensity=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_singular_run_df = singular_run_df.copy()\n",
    "_singular_run_df[NETWORK_START_KEYS] = _singular_run_df[NETWORK_START_KEYS] / 1024\n",
    "\n",
    "draw_graph(\n",
    "    title=\"Evaluation Runs Average\",\n",
    "    data=_singular_run_df[NETWORK_START_KEYS + [STAGE_KEY]],\n",
    "    y_label=\"Network Change (GB)\",\n",
    "    x_lim=(0, max(_singular_run_df.index)),\n",
    "    show_stages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df.copy()\n",
    "_df[NETWORK_START_KEYS] = _df[NETWORK_START_KEYS] / 1024\n",
    "\n",
    "draw_graph(\n",
    "    title=\"Evaluation Runs Average\",\n",
    "    data=_df[NETWORK_START_KEYS + [STAGE_KEY]],\n",
    "    y_label=\"Network Change (GB)\",\n",
    "    x_lim=(0, max(_df.index)),\n",
    "    #show_stages=True,\n",
    "    #stages_color_intensity=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(\n",
    "    title=\"Evaluation Runs Average\",\n",
    "    data=singular_run_df[NETWORK_LAST_KEYS + [STAGE_KEY]],\n",
    "    y_label=\"Network Changes Between Measurements (MB)\",\n",
    "    x_lim=(0, max(singular_run_df.index)),\n",
    "    y_lim=(0, 1000),\n",
    "    show_stages=True,\n",
    "    stages_color_height=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(\n",
    "    title=\"Evaluation Runs Average\",\n",
    "    data=df[NETWORK_LAST_KEYS + [STAGE_KEY]],\n",
    "    y_label=\"Network Changes Between Measurements (MB)\",\n",
    "    x_lim=(0, max(df.index)),\n",
    "    y_lim=(0, 1000),\n",
    "    #show_stages=True,\n",
    "    #stages_color_intensity=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_trained_model_comparison_graph(\n",
    "    data=trained_model_df,\n",
    "    key=ACCURACY_KEY,\n",
    "    y_label=\"Accuracy (%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_trained_model_comparison_graph(\n",
    "    data=trained_model_df,\n",
    "    key=LOSS_KEY,\n",
    "    y_label=\"Loss (%)\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
